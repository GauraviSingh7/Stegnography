# Probabilistic Entity Steganography

This repository contains a Python implementation of a **steganography technique** that encodes a secret message into a seemingly innocuous sentence. The method leverages a **probabilistic ontology of named entities** to hide a bitstream, which is then embedded into a sentence generated by a **Large Language Model (LLM)**.

---

## üìú Overview
The core idea is to convert a secret message (e.g., `"M"`) into its **binary representation** (`01001101`). This bitstream is then treated as a **binary fraction** (e.g., `0.01001101...`), which is a number between 0 and 1. This number is used to select a specific **named entity** (like `"Lake Huron"`) from a hierarchical ontology file (`ontology_with_probabilities.json`).

An LLM (Google's **Gemini**) then generates a **natural-sounding sentence** containing the selected entity. At the receiving end, the entity can be extracted from the sentence, its corresponding probability interval recalculated from the ontology, and the original bitstream decoded ‚Äî revealing the **secret message**.

---

## ‚ú® Core Concepts

The pipeline is divided into several key phases:

### 1. Embedding (Sampler)
- The secret text message is converted into a bitstream.
- This bitstream is treated as a binary fraction to create a Decimal value between 0 and 1.
- The script traverses a probabilistic ontology, narrowing down a probability interval `[low, high)` until a **leaf-node entity** is selected that corresponds to the secret value.

### 2. Generation & Verification (GA & CA)
- A **Generation Agent (GA)**, powered by the Gemini API, is prompted to create a fluent, natural-sounding sentence that must contain the selected entity.
- A **Check Agent (CA)** then evaluates this sentence to ensure it is compliant ‚Äî it must contain the target entity and no other recognizable named entities (locations, people, organizations, etc.).
- If the sentence is non-compliant, the script attempts to regenerate it with feedback up to a set number of attempts.

### 3. Extraction & Decoding (EA & Decoder)
- An **Extraction Agent (EA)** deterministically finds and extracts the named entity from the final sentence. This is done via a reliable regex search against the list of all known entities.
- The **Decoder** uses the extracted entity's name to find its path in the ontology, recalculate its exact probability interval, and reverse the embedding process to reconstruct the original bitstream.
- The bitstream is converted back to text to reveal the original secret.

---

## üöÄ Getting Started

### Prerequisites
- Python 3.7+
- An active **Google AI Studio API key**

### Installation & Setup

1. **Clone the repository:**
   ```bash
   git clone https://github.com/GauraviSingh7/Stegnography.git
   cd Stegnography
   ```

2. **Install the required Python libraries:**
   ```bash
   pip install google-generativeai python-dotenv
   ```

3. **Create an environment file:**  
   Create a file named `.env` in the root of the project directory and add your Gemini API key:
   ```bash
   GEMINI_API_KEY="YOUR_API_KEY_HERE"
   ```

4. **Add the Ontology File:**  
   Ensure `ontology_with_probabilities.json` is present in the same directory as the script. This file is crucial for the encoding and decoding process.

---

## ‚ñ∂Ô∏è Running the Script
Execute the script from your terminal:
```bash
python bitstreamWorking.py
```
To change the secret message, modify the `secret_message` variable inside the `if __name__ == '__main__':` block at the bottom of the script.

### Note on Message Length
This method's ability to store information is determined by the **probability of the selected entity**. Entities with smaller probabilities (narrower intervals) can store more bits. The script will warn you if your secret message is too long for the capacity of the selected entity. For testing, start with **short, single-character messages**.

---

## üìù Example Flow (for secret message `"M"`)

1. Original Secret: `'M'`
2. Original Bitstream (8 bits): `01001101`
3. Converted to Decimal: `0.30078125`
4. Sampler selects Entity: `'Lake Huron'`
5. Generation Agent creates sentence: `"Lake Huron is a popular destination."`
6. Check Agent verifies the sentence is compliant.
7. Extraction Agent identifies `'Lake Huron'` from the sentence.
8. Decoder finds `'Lake Huron'` in the ontology.
9. It calculates the entity's probability interval: `[0.300617..., 0.301128...)`
10. It converts the interval's lower bound back to binary.
11. Decoded 8 bits: `01001101`
12. Decoded Message: `'M'`

**RESULT:** ‚úÖ *Perfect match ‚Äî Bitstreams are identical!*

---

## üìÇ File Structure
```
.
‚îú‚îÄ‚îÄ bitstreamWorking.py              # The main Python script
‚îú‚îÄ‚îÄ ontology_with_probabilities.json    # The probabilistic knowledge graph
‚îú‚îÄ‚îÄ .env                                # Your environment file for API keys
‚îî‚îÄ‚îÄ README.md                           # This file
```

